{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6a1e0fb-31aa-462d-9860-b6d7963d3ce0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "---\n",
    "Author: Mustapha Bouhsen <br>\n",
    "[LinkedIn](https://www.linkedin.com/in/mustapha-bouhsen/)<br>\n",
    "[Git](https://github.com/mus514)<br>\n",
    "Date: February 14, 2024<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c37ce64-7be6-4c97-9b71-6b27b9fbfc18",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run Repos/bouhsen.m@gmail.com/ML_Pipeline_Hub/library/garch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf4acc20-31d8-4273-b1d9-0f5ba2e1080e",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run Repos/bouhsen.m@gmail.com/ML_Pipeline_Hub/library/daily_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f472c7d9-d27d-4be3-9486-61c3ba9a5628",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Creating table containg the log return for each stock prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "935c45b4-5dd0-4885-b3b1-6afd7f4420e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The log return is given by :\n",
    "\n",
    "$$\n",
    "r_t = log(\\frac{P_t}{P_{t-1}})\n",
    "$$\n",
    "\n",
    "Where $P_t$ is the stock price at time t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5920d8b2-cf1b-4ea1-abdb-9f4be5a7d764",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Set the prod folder path\n",
    "#-----------------------------------------\n",
    "raw_folder_path = \"/mnt/raw/\"\n",
    "prod_folder_path = \"/mnt/prod/\"\n",
    "\n",
    "stocks = [\"aapl\", \"amzn\", \"googl\", \"msft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a06bb3a-cf0e-464c-ac67-fdbde23a61f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Loading the stocks_prices table and calculate the log return for each stock\n",
    "#-----------------------------------------\n",
    "df = spark.sql(\"SELECT * FROM stocks_prices\")\n",
    "\n",
    "# Calculate the log return for each stock\n",
    "for stock in stocks:\n",
    "    # Order by date\n",
    "    df = df.orderBy(\"date\")\n",
    "    # Create a window specification\n",
    "    windowSpec = Window.orderBy(\"date\")\n",
    "    # Calculate log return\n",
    "    col_expr = F.log(df[stock]) - F.lag(F.log(df[stock])).over(windowSpec)\n",
    "    # Round the return\n",
    "    col_expr_rounded = F.round(col_expr, 6)\n",
    "    # Assign the new column to the dataframe\n",
    "    df = df.withColumn(stock, col_expr_rounded)\n",
    "\n",
    "# Delete The Null row\n",
    "df = df.na.drop()\n",
    "\n",
    "# Check if the table exists\n",
    "if spark.catalog.tableExists(\"stocks_returns\"):\n",
    "    # Drop the existing table\n",
    "    spark.sql(f\"DROP TABLE stocks_returns\")\n",
    "    print(f'Dropped table: stocks_returns')\n",
    "\n",
    "\n",
    "# Create the table\n",
    "df.write.format(\"parquet\").saveAsTable(\"stocks_returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21b02ae1-ede5-403a-aa4e-ca6388916564",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date</th><th>aapl</th><th>amzn</th><th>msft</th><th>googl</th></tr></thead><tbody><tr><td>2024-02-15</td><td>-0.001576</td><td>-0.006926</td><td>-0.007181</td><td>-0.021961</td></tr><tr><td>2024-02-14</td><td>-0.004821</td><td>0.013781</td><td>0.009619</td><td>0.005497</td></tr><tr><td>2024-02-13</td><td>-0.011338</td><td>-0.021703</td><td>-0.021764</td><td>-0.016333</td></tr><tr><td>2024-02-12</td><td>-0.009043</td><td>-0.012169</td><td>-0.012659</td><td>-0.009915</td></tr><tr><td>2024-02-09</td><td>0.004086</td><td>0.026782</td><td>0.015432</td><td>0.020957</td></tr><tr><td>2024-02-08</td><td>-0.005771</td><td>-0.004055</td><td>1.45E-4</td><td>0.002539</td></tr><tr><td>2024-02-07</td><td>5.81E-4</td><td>0.008125</td><td>0.02089</td><td>0.009943</td></tr><tr><td>2024-02-06</td><td>0.008595</td><td>-0.006835</td><td>-3.94E-4</td><td>0.002919</td></tr><tr><td>2024-02-05</td><td>0.009799</td><td>-0.008769</td><td>-0.013638</td><td>0.009089</td></tr><tr><td>2024-02-02</td><td>-0.00542</td><td>0.075726</td><td>0.018259</td><td>0.008605</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2024-02-15",
         -0.001576,
         -0.006926,
         -0.007181,
         -0.021961
        ],
        [
         "2024-02-14",
         -0.004821,
         0.013781,
         0.009619,
         0.005497
        ],
        [
         "2024-02-13",
         -0.011338,
         -0.021703,
         -0.021764,
         -0.016333
        ],
        [
         "2024-02-12",
         -0.009043,
         -0.012169,
         -0.012659,
         -0.009915
        ],
        [
         "2024-02-09",
         0.004086,
         0.026782,
         0.015432,
         0.020957
        ],
        [
         "2024-02-08",
         -0.005771,
         -0.004055,
         1.45E-4,
         0.002539
        ],
        [
         "2024-02-07",
         5.81E-4,
         0.008125,
         0.02089,
         0.009943
        ],
        [
         "2024-02-06",
         0.008595,
         -0.006835,
         -3.94E-4,
         0.002919
        ],
        [
         "2024-02-05",
         0.009799,
         -0.008769,
         -0.013638,
         0.009089
        ],
        [
         "2024-02-02",
         -0.00542,
         0.075726,
         0.018259,
         0.008605
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 27
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "aapl",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "amzn",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "msft",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "googl",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Disply the stocks_returns\n",
    "SELECT *\n",
    "FROM stocks_returns\n",
    "ORDER BY date DESC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c1bde1-d499-45a1-9189-8e9269c965da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Write the returns in the prod\n",
    "#-----------------------------------------\n",
    "# Temp folder to save temp parquet files\n",
    "temp_folder = prod_folder_path + f\"temp/\"\n",
    "\n",
    "# write data frame to csv\n",
    "df.write.mode(\"overwrite\").option(\"header\", \"True\").csv(temp_folder)\n",
    "\n",
    "# get all files path ending with .parquet\n",
    "files_paths = get_files_paths_from_folders(temp_folder, \".csv\")\n",
    "            \n",
    "# Copy parquet files to final destination\n",
    "ingest_and_transform_to_parquet(files_paths, prod_folder_path, \"returns\")\n",
    "\n",
    "# delete the temp folder\n",
    "delete_contents_recursively(temp_folder)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2067982540407847,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "daily_returns_sql_tables",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
