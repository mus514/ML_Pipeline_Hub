{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6a1e0fb-31aa-462d-9860-b6d7963d3ce0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "---\n",
    "Author: Mustapha Bouhsen <br>\n",
    "[LinkedIn](https://www.linkedin.com/in/mustapha-bouhsen/)<br>\n",
    "[Git](https://github.com/mus514)<br>\n",
    "Date: February 14, 2024<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c37ce64-7be6-4c97-9b71-6b27b9fbfc18",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run Repos/bouhsen.m@gmail.com/ML_Pipeline_Hub/library/garch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf4acc20-31d8-4273-b1d9-0f5ba2e1080e",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run Repos/bouhsen.m@gmail.com/ML_Pipeline_Hub/library/daily_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d46b064f-80a6-4735-9740-c5b073492d3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Set the table folder path\n",
    "#-----------------------------------------\n",
    "tables_folder_path = \"/mnt/tables/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25a46de1-69e4-470b-b173-690fb4354c62",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Join stocks tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bea2dc21-2257-4357-bad2-a74b8838fdde",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date</th><th>open</th><th>high</th><th>low</th><th>close</th><th>adj_close</th><th>volume</th></tr></thead><tbody><tr><td>2004-01-02</td><td>0.384821</td><td>0.388393</td><td>0.378214</td><td>0.38</td><td>0.32170784</td><td>1.446424E8</td></tr><tr><td>2004-01-05</td><td>0.3825</td><td>0.399821</td><td>0.3825</td><td>0.395893</td><td>0.33516276</td><td>3.950184E8</td></tr><tr><td>2004-01-06</td><td>0.397321</td><td>0.400357</td><td>0.387679</td><td>0.394464</td><td>0.33395284</td><td>5.09348E8</td></tr><tr><td>2004-01-07</td><td>0.394643</td><td>0.407679</td><td>0.391607</td><td>0.403393</td><td>0.3415123</td><td>5.8687437E8</td></tr><tr><td>2004-01-08</td><td>0.407857</td><td>0.42375</td><td>0.404464</td><td>0.417143</td><td>0.35315302</td><td>4.603032E8</td></tr><tr><td>2004-01-09</td><td>0.414821</td><td>0.430893</td><td>0.406964</td><td>0.410714</td><td>0.34771028</td><td>4.274592E8</td></tr><tr><td>2004-01-12</td><td>0.415179</td><td>0.428571</td><td>0.4125</td><td>0.42375</td><td>0.35874656</td><td>4.875472E8</td></tr><tr><td>2004-01-13</td><td>0.441071</td><td>0.443571</td><td>0.426071</td><td>0.430714</td><td>0.36464235</td><td>6.7901683E8</td></tr><tr><td>2004-01-14</td><td>0.435714</td><td>0.438214</td><td>0.424643</td><td>0.432143</td><td>0.3658521</td><td>6.200432E8</td></tr><tr><td>2004-01-15</td><td>0.409107</td><td>0.417857</td><td>0.401786</td><td>0.408036</td><td>0.34544307</td><td>1.01820877E9</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2004-01-02",
         0.384821,
         0.388393,
         0.378214,
         0.38,
         0.32170784,
         1.446424E8
        ],
        [
         "2004-01-05",
         0.3825,
         0.399821,
         0.3825,
         0.395893,
         0.33516276,
         3.950184E8
        ],
        [
         "2004-01-06",
         0.397321,
         0.400357,
         0.387679,
         0.394464,
         0.33395284,
         5.09348E8
        ],
        [
         "2004-01-07",
         0.394643,
         0.407679,
         0.391607,
         0.403393,
         0.3415123,
         5.8687437E8
        ],
        [
         "2004-01-08",
         0.407857,
         0.42375,
         0.404464,
         0.417143,
         0.35315302,
         4.603032E8
        ],
        [
         "2004-01-09",
         0.414821,
         0.430893,
         0.406964,
         0.410714,
         0.34771028,
         4.274592E8
        ],
        [
         "2004-01-12",
         0.415179,
         0.428571,
         0.4125,
         0.42375,
         0.35874656,
         4.875472E8
        ],
        [
         "2004-01-13",
         0.441071,
         0.443571,
         0.426071,
         0.430714,
         0.36464235,
         6.7901683E8
        ],
        [
         "2004-01-14",
         0.435714,
         0.438214,
         0.424643,
         0.432143,
         0.3658521,
         6.200432E8
        ],
        [
         "2004-01-15",
         0.409107,
         0.417857,
         0.401786,
         0.408036,
         0.34544307,
         1.01820877E9
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 30
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "open",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "high",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "low",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "close",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "adj_close",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "volume",
         "type": "\"float\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    date, open, high, low, close, adj_close, volume\n",
    "FROM\n",
    "aapl\n",
    "LIMIT 10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e41036b-f8fa-4331-a91f-838cf2313fa5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 41
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "/***************************************\n",
    "*\n",
    "* Creating join table for stocks information\n",
    "* \n",
    "****************************************/\n",
    "DROP TABLE IF EXISTS stocks;\n",
    "\n",
    "CREATE TABLE stocks AS\n",
    "\n",
    "SELECT\n",
    "    date, open, high, low, close, adj_close, volume,\n",
    "    'aapl' AS stock\n",
    "FROM\n",
    "    aapl\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT\n",
    "    date, open, high, low, close, adj_close, volume,\n",
    "    'amzn' AS stock\n",
    "FROM\n",
    "    amzn\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT\n",
    "    date, open, high, low, close, adj_close, volume,\n",
    "    'googl' AS stock\n",
    "FROM\n",
    "    googl\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT\n",
    "    date, open, high, low, close, adj_close, volume,\n",
    "    'msft' AS stock\n",
    "FROM\n",
    "    msft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ca89644-0cba-41ae-9cca-91d4fe99dde0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Loading the stocks table and save it in csv\n",
    "#-----------------------------------------\n",
    "df = spark.sql(\"SELECT * FROM stocks\")\n",
    "\n",
    "\n",
    "# Temp folder to save temp parquet files\n",
    "temp_folder = tables_folder_path + f\"temp/\"\n",
    "\n",
    "# write data frame to csv\n",
    "df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"True\").csv(temp_folder)\n",
    "\n",
    "#get all files path ending with .parquet\n",
    "files_paths = get_files_paths_from_folders(temp_folder, \".csv\")\n",
    "            \n",
    "# Copy parquet files to final destination\n",
    "ingest_and_transform_to_parquet(files_paths, tables_folder_path, \"stocks\")\n",
    "\n",
    "# delete the temp folder\n",
    "delete_contents_recursively(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bac31b24-4b09-4780-becc-ea39b1bf2b25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Join Returns tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a725fa5d-de7d-4287-a49f-ebde6bfd3f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 43
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "/***************************************\n",
    "*\n",
    "* Creating join table for returns\n",
    "* \n",
    "****************************************/\n",
    "DROP TABLE IF EXISTS returns;\n",
    "\n",
    "CREATE TABLE returns AS\n",
    "\n",
    "SELECT \n",
    "    date,\n",
    "    return,\n",
    "    stock\n",
    "FROM (\n",
    "    SELECT \n",
    "        date,\n",
    "        aapl,\n",
    "        amzn,\n",
    "        googl,\n",
    "        msft\n",
    "    FROM stocks_returns\n",
    ") AS Source\n",
    "UNPIVOT (\n",
    "    Return FOR stock IN (aapl, amzn, googl, msft)\n",
    ") AS UnpivotedTable;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e065678-2b6c-4c03-90b9-1709eea117a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Loading the stocks table and save it in csv\n",
    "#-----------------------------------------\n",
    "df = spark.sql(\"SELECT * FROM returns\")\n",
    "\n",
    "\n",
    "# Temp folder to save temp parquet files\n",
    "temp_folder = tables_folder_path + f\"temp/\"\n",
    "\n",
    "# write data frame to csv\n",
    "df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"True\").csv(temp_folder)\n",
    "\n",
    "#get all files path ending with .parquet\n",
    "files_paths = get_files_paths_from_folders(temp_folder, \".csv\")\n",
    "            \n",
    "# Copy parquet files to final destination\n",
    "ingest_and_transform_to_parquet(files_paths, tables_folder_path, \"returns\")\n",
    "\n",
    "# delete the temp folder\n",
    "delete_contents_recursively(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c439b79f-9eac-4628-9de7-2939ac8d075f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Join Volatilities tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32287408-c768-4179-b768-01de8ba8b3cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 45
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "/***************************************\n",
    "*\n",
    "* Creating join table for volatilities\n",
    "* \n",
    "****************************************/\n",
    "DROP TABLE IF EXISTS volatilities;\n",
    "\n",
    "CREATE TABLE volatilities AS\n",
    "\n",
    "SELECT \n",
    "    date,\n",
    "    volatility,\n",
    "    stock\n",
    "FROM (\n",
    "    SELECT \n",
    "        date,\n",
    "        aapl,\n",
    "        amzn,\n",
    "        googl,\n",
    "        msft\n",
    "    FROM stocks_volatility\n",
    ") AS Source\n",
    "UNPIVOT (\n",
    "    volatility FOR stock IN (aapl, amzn, googl, msft)\n",
    ") AS UnpivotedTable;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00232308-980b-44f1-bef9-6b2243f1def5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Loading the volatility table and save it in csv\n",
    "#-----------------------------------------\n",
    "df = spark.sql(\"SELECT * FROM volatilities\")\n",
    "\n",
    "\n",
    "# Temp folder to save temp parquet files\n",
    "temp_folder = tables_folder_path + f\"temp/\"\n",
    "\n",
    "# write data frame to csv\n",
    "df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"True\").csv(temp_folder)\n",
    "\n",
    "#get all files path ending with .parquet\n",
    "files_paths = get_files_paths_from_folders(temp_folder, \".csv\")\n",
    "            \n",
    "# Copy parquet files to final destination\n",
    "ingest_and_transform_to_parquet(files_paths, tables_folder_path, \"volatilities\")\n",
    "\n",
    "# delete the temp folder\n",
    "delete_contents_recursively(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5835b89-7f98-40ad-8aff-66d5309af144",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Join Monte-Carlo simulation tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5731994-3aa0-4b7e-b13f-7595db631d93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tables = [\"aapl_simulation\", \"amzn_simulation\", \"googl_simulation\", \"msft_simulation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e3f84d1-cb4f-42bd-876f-250ab9275fad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped table: aapl_simulation_avr\nDropped table: amzn_simulation_avr\nDropped table: googl_simulation_avr\nDropped table: msft_simulation_avr\n"
     ]
    }
   ],
   "source": [
    "prod_folder_path = \"/dbfs/mnt/prod/\"\n",
    "for stock in tables:\n",
    "    # improt data\n",
    "    df = pd.read_csv(prod_folder_path + stock + \".csv\")\n",
    "\n",
    "    df_avr = pd.DataFrame()\n",
    "    # Get the last price of the stock\n",
    "    df_avr[\"date\"] =df[\"date\"]\n",
    "\n",
    "    # average \n",
    "    df_avr[\"adj_stock\"] = df.drop('date', axis=1).values.mean(axis=1)\n",
    "\n",
    "    # Convert simulated prices to a Spark DataFrame with the specified schema\n",
    "    df = spark.createDataFrame(df_avr)\n",
    "\n",
    "    # Define the table name for the Monte Carlo simulation results\n",
    "    table_name = f'{stock}_avr'\n",
    "\n",
    "    # Check if the table already exists in the Spark catalog\n",
    "    if spark.catalog.tableExists(f\"{table_name}\"):\n",
    "        # If the table exists, drop it\n",
    "        spark.sql(f\"DROP TABLE {table_name}\")\n",
    "        print(f'Dropped table: {table_name}')\n",
    "\n",
    "    # Create a new table with the simulated prices\n",
    "    df.write.format(\"parquet\").saveAsTable(table_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7a29518-4c38-49f7-a635-9ea30e5d1b88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 49
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "/***************************************\n",
    "*\n",
    "* Creating join table for Monte-Carlo information\n",
    "* \n",
    "****************************************/\n",
    "\n",
    "DROP TABLE IF EXISTS simulation_avr;\n",
    "\n",
    "CREATE TABLE simulation_avr AS\n",
    "\n",
    "SELECT\n",
    "    *,\n",
    "    'aapl' AS stock\n",
    "FROM\n",
    "    aapl_simulation_avr\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT\n",
    "    *,\n",
    "    'amzn' AS stock\n",
    "FROM\n",
    "    amzn_simulation_avr\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT\n",
    "    *,\n",
    "    'googl' AS stock\n",
    "FROM\n",
    "    googl_simulation_avr\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT\n",
    "    *,\n",
    "    'msft' AS stock\n",
    "FROM\n",
    "    msft_simulation_avr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23532777-c65d-4310-b2a1-f5b06d6332e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Loading the simulation monte-carlo table and save it in csv\n",
    "#-----------------------------------------\n",
    "df = spark.sql(\"SELECT * FROM simulation_avr\")\n",
    "\n",
    "\n",
    "# Temp folder to save temp parquet files\n",
    "temp_folder = tables_folder_path + f\"temp/\"\n",
    "\n",
    "# write data frame to csv\n",
    "df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"True\").csv(temp_folder)\n",
    "\n",
    "#get all files path ending with .parquet\n",
    "files_paths = get_files_paths_from_folders(temp_folder, \".csv\")\n",
    "            \n",
    "# Copy parquet files to final destination\n",
    "ingest_and_transform_to_parquet(files_paths, tables_folder_path, \"simulation_avr\")\n",
    "\n",
    "# delete the temp folder\n",
    "delete_contents_recursively(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "856c5595-432b-495e-a228-81131dce462f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Join Monte-Carlo simulation of the last prices tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7dc432a-009a-48a9-b7ae-2fdbd11fac5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 32
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "/***************************************\n",
    "*\n",
    "* Creating join table for volatilities\n",
    "* \n",
    "****************************************/\n",
    "DROP TABLE IF EXISTS last_prices;\n",
    "\n",
    "CREATE TABLE last_prices AS\n",
    "\n",
    "SELECT \n",
    "    simulation,\n",
    "    stock\n",
    "FROM (\n",
    "    SELECT \n",
    "        aapl,\n",
    "        amzn,\n",
    "        googl,\n",
    "        msft\n",
    "    FROM simulation_of_last_prices\n",
    ") AS Source\n",
    "UNPIVOT (\n",
    "    simulation FOR stock IN (aapl, amzn, googl, msft)\n",
    ") AS UnpivotedTable;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d313497c-f2d1-4627-bb54-1c85f27e6023",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Loading the last prices simulations table and save it in csv\n",
    "#-----------------------------------------\n",
    "df = spark.sql(\"SELECT * FROM last_prices\")\n",
    "\n",
    "\n",
    "# Temp folder to save temp parquet files\n",
    "temp_folder = tables_folder_path + f\"temp/\"\n",
    "\n",
    "# write data frame to csv\n",
    "df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"True\").csv(temp_folder)\n",
    "\n",
    "#get all files path ending with .parquet\n",
    "files_paths = get_files_paths_from_folders(temp_folder, \".csv\")\n",
    "            \n",
    "# Copy parquet files to final destination\n",
    "ingest_and_transform_to_parquet(files_paths, tables_folder_path, \"last_prices\")\n",
    "\n",
    "# delete the temp folder\n",
    "delete_contents_recursively(temp_folder)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 907270414275852,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "sql_join_tables",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
